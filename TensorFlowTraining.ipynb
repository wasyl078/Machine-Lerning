{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer: this is not my code, I'm just trying new things and watching some tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression: Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset.\n",
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data\n",
    "y_train = dftrain.pop('survived')\n",
    "y_eval = dfeval.pop('survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression: Some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18541760348>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dftrain.age.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18543882888>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dftrain.sex.value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x185439244c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dftrain[\"class\"].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '% survive')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat([dftrain, y_train], axis=1).groupby('sex').survived.mean().plot(kind='barh').set_xlabel('% survive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression: Creating Special DataSets for TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
    "                       'embark_town', 'alone']\n",
    "NUMERIC_COLUMNS = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "    vocabulary = dftrain[feature_name].unique()  # gets a list of all unique values from given feature column\n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "\n",
    "    \n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "    def input_function():  # inner function, this will be returned\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000)  # randomize order of data\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n",
    "        return ds  # return a batch of the dataset\n",
    "    return input_function  # return a function object for use\n",
    "\n",
    "train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression: Creating and running model\n",
    "\n",
    "1. linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "2. linear_est.train(train_input_fn)\n",
    "3. result = linear_est.evaluate(eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\WASILE~1\\AppData\\Local\\Temp\\tmpyeq2qx6p\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\WASILE~1\\\\AppData\\\\Local\\\\Temp\\\\tmpyeq2qx6p', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "# We create a linear estimtor by passing the feature columns we created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7310606\n"
     ]
    }
   ],
   "source": [
    "linear_est.train(train_input_fn)  # train\n",
    "result = linear_est.evaluate(eval_input_fn)  # get model metrics/stats by testing on tetsing data\n",
    "\n",
    "clear_output()  # clears consoke output\n",
    "print(result['accuracy'])  # the result variable is simply a dict of stats about our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: Loading and creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "# Lets define some constants to help us later on\n",
    "\n",
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "# Here we use keras (a module inside of TensorFlow) to grab our datasets and read them into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: creating and running DNNclassifier model\n",
    "1. classifier = tf.estimator.DNNClassifier(feature_columns=my_feature_columns, hidden_units=[30, 10], n_classes=3)\n",
    "2. classifier.train(input_fn=lambda: input_fn(train, train_y, training=True), steps=5000)\n",
    "3. eval_result = classifier.evaluate(input_fn=lambda: input_fn(test, test_y, training=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\WASILE~1\\AppData\\Local\\Temp\\tmpbc0sr0_6\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\WASILE~1\\\\AppData\\\\Local\\\\Temp\\\\tmpbc0sr0_6', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\WASILE~1\\AppData\\Local\\Temp\\tmpbc0sr0_6\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.3609443, step = 0\n",
      "INFO:tensorflow:global_step/sec: 435.325\n",
      "INFO:tensorflow:loss = 1.1252447, step = 100 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.62\n",
      "INFO:tensorflow:loss = 1.0641415, step = 200 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.836\n",
      "INFO:tensorflow:loss = 1.0339923, step = 300 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.335\n",
      "INFO:tensorflow:loss = 1.0138246, step = 400 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 527.18\n",
      "INFO:tensorflow:loss = 0.9821361, step = 500 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 521.702\n",
      "INFO:tensorflow:loss = 0.95814764, step = 600 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.544\n",
      "INFO:tensorflow:loss = 0.93954384, step = 700 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.157\n",
      "INFO:tensorflow:loss = 0.9372227, step = 800 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.663\n",
      "INFO:tensorflow:loss = 0.9018415, step = 900 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.432\n",
      "INFO:tensorflow:loss = 0.8943147, step = 1000 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.084\n",
      "INFO:tensorflow:loss = 0.8939068, step = 1100 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.147\n",
      "INFO:tensorflow:loss = 0.85731125, step = 1200 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.837\n",
      "INFO:tensorflow:loss = 0.8570866, step = 1300 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.837\n",
      "INFO:tensorflow:loss = 0.8320215, step = 1400 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.147\n",
      "INFO:tensorflow:loss = 0.8191176, step = 1500 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.837\n",
      "INFO:tensorflow:loss = 0.80212235, step = 1600 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.145\n",
      "INFO:tensorflow:loss = 0.8034315, step = 1700 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.665\n",
      "INFO:tensorflow:loss = 0.78049046, step = 1800 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.619\n",
      "INFO:tensorflow:loss = 0.76130676, step = 1900 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 529.996\n",
      "INFO:tensorflow:loss = 0.75698566, step = 2000 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.159\n",
      "INFO:tensorflow:loss = 0.7445251, step = 2100 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.432\n",
      "INFO:tensorflow:loss = 0.7319595, step = 2200 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.274\n",
      "INFO:tensorflow:loss = 0.73664093, step = 2300 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.274\n",
      "INFO:tensorflow:loss = 0.71081334, step = 2400 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.082\n",
      "INFO:tensorflow:loss = 0.72581947, step = 2500 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 532.839\n",
      "INFO:tensorflow:loss = 0.6945467, step = 2600 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.431\n",
      "INFO:tensorflow:loss = 0.69110054, step = 2700 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.359\n",
      "INFO:tensorflow:loss = 0.6944475, step = 2800 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 532.833\n",
      "INFO:tensorflow:loss = 0.6662961, step = 2900 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.273\n",
      "INFO:tensorflow:loss = 0.6566207, step = 3000 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.62\n",
      "INFO:tensorflow:loss = 0.6826601, step = 3100 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.619\n",
      "INFO:tensorflow:loss = 0.6456853, step = 3200 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.146\n",
      "INFO:tensorflow:loss = 0.6487216, step = 3300 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.838\n",
      "INFO:tensorflow:loss = 0.63246906, step = 3400 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.837\n",
      "INFO:tensorflow:loss = 0.62515396, step = 3500 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 530.011\n",
      "INFO:tensorflow:loss = 0.6135702, step = 3600 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 518.997\n",
      "INFO:tensorflow:loss = 0.6299543, step = 3700 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.146\n",
      "INFO:tensorflow:loss = 0.5817521, step = 3800 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.273\n",
      "INFO:tensorflow:loss = 0.6028878, step = 3900 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.619\n",
      "INFO:tensorflow:loss = 0.60138357, step = 4000 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 529.966\n",
      "INFO:tensorflow:loss = 0.59168065, step = 4100 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.664\n",
      "INFO:tensorflow:loss = 0.5763299, step = 4200 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 540.048\n",
      "INFO:tensorflow:loss = 0.5722624, step = 4300 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.836\n",
      "INFO:tensorflow:loss = 0.54484814, step = 4400 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.275\n",
      "INFO:tensorflow:loss = 0.5592948, step = 4500 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.584\n",
      "INFO:tensorflow:loss = 0.5698008, step = 4600 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.837\n",
      "INFO:tensorflow:loss = 0.5455384, step = 4700 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 540.049\n",
      "INFO:tensorflow:loss = 0.55050814, step = 4800 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.836\n",
      "INFO:tensorflow:loss = 0.539398, step = 4900 (0.189 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\WASILE~1\\AppData\\Local\\Temp\\tmpbc0sr0_6\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.5358011.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x1861aed4ec8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=5000)\n",
    "# We include a lambda to avoid creating an inner function previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-11T00:44:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\WASILE~1\\AppData\\Local\\Temp\\tmpbc0sr0_6\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.21419s\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-11-00:44:32\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.53333336, average_loss = 0.68754745, global_step = 5000, loss = 0.68754745\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\WASILE~1\\AppData\\Local\\Temp\\tmpbc0sr0_6\\model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 0.533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier: Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type numeric values as prompted.\n",
      "SepalLength: 1.2\n",
      "SepalWidth: 2.3\n",
      "PetalLength: 0.1\n",
      "PetalWidth: 0.1\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\WASILE~1\\AppData\\Local\\Temp\\tmpbc0sr0_6\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Setosa\" (55.5%)\n"
     ]
    }
   ],
   "source": [
    "def input_fn(features, batch_size=256):\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "predict = {}\n",
    "\n",
    "print(\"Please type numeric values as prompted.\")\n",
    "for feature in features:\n",
    "    valid = True\n",
    "    while valid: \n",
    "        val = input(feature + \": \")\n",
    "        if not val.isdigit(): valid = False\n",
    "\n",
    "    predict[feature] = [float(val)]\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
    "for pred_dict in predictions:\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
    "        SPECIES[class_id], 100 * probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov Model: /datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions  # making a shortcut for later on\n",
    "initial_distribution = tfd.Categorical(probs=[0.8, 0.2])  # Refer to point 2 above\n",
    "transition_distribution = tfd.Categorical(probs=[[0.3, 0.2],\n",
    "                                                 [0.2, 0.8]])  # refer to points 3 and 4 above\n",
    "observation_distribution = tfd.Normal(loc=[0., 15.], scale=[5., 10.])  # refer to point 5 above\n",
    "\n",
    "# the loc argument represents the mean and the scale is the standard devitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov Model: Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tfd.HiddenMarkovModel(\n",
    "    initial_distribution=initial_distribution,\n",
    "    transition_distribution=transition_distribution,\n",
    "    observation_distribution=observation_distribution,\n",
    "    num_steps=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.       7.2      8.88     9.552    9.820799 9.928319 9.971326]\n"
     ]
    }
   ],
   "source": [
    "mean = model.mean()\n",
    "\n",
    "# due to the way TensorFlow works on a lower level we need to evaluate part of the graph\n",
    "# from within a session to see the value of this tensor\n",
    "\n",
    "# in the new version of tensorflow we need to use tf.compat.v1.Session() rather than just tf.Session()\n",
    "with tf.compat.v1.Session() as sess:  \n",
    "    print(mean.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network: loading and creating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist  # load dataset\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()  # split into tetsing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network: creating network's layers, compiling and training/fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),  # input layer (1)\n",
    "    keras.layers.Dense(128, activation='relu'),  # hidden layer (2)\n",
    "    keras.layers.Dense(10, activation='softmax') # output layer (3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 989us/step - loss: 0.4943 - accuracy: 0.8260\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 977us/step - loss: 0.3731 - accuracy: 0.8660\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 965us/step - loss: 0.3366 - accuracy: 0.8766\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 979us/step - loss: 0.3130 - accuracy: 0.8850\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 974us/step - loss: 0.2939 - accuracy: 0.8913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18544440488>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5)  # we pass the data, labels and epochs and watch the magic!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network: checking accuracy on eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 991us/step - loss: 0.3534 - accuracy: 0.8736\n",
      "Test accuracy: 0.8736000061035156\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=1) \n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network: Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pick a number: 5\n",
      "Excpected: Trouser\n",
      "Guess: Trouser\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(test_images)\n",
    "\n",
    "COLOR = 'white'\n",
    "plt.rcParams['text.color'] = COLOR\n",
    "plt.rcParams['axes.labelcolor'] = COLOR\n",
    "\n",
    "def predict(model, image, correct_label):\n",
    "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    prediction = model.predict(np.array([image]))\n",
    "    predicted_class = class_names[np.argmax(prediction)]\n",
    "    print(\"Excpected:\", class_names[correct_label])\n",
    "    print(\"Guess:\", predicted_class)\n",
    "    show_image(image, class_names[correct_label], predicted_class)\n",
    "\n",
    "\n",
    "def show_image(img, label, guess):\n",
    "    plt.figure()\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "    plt.title(\"Excpected: \" + label)\n",
    "    plt.xlabel(\"Guess: \" + guess)\n",
    "    plt.colorbar()\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_number():\n",
    "    while True:\n",
    "        num = input(\"Pick a number: \")\n",
    "        if num.isdigit():\n",
    "            num = int(num)\n",
    "        if 0 <= num <= 1000:\n",
    "            return int(num)\n",
    "        else:\n",
    "            print(\"Try again...\")\n",
    "\n",
    "num = get_number()\n",
    "image = test_images[num]\n",
    "label = test_labels[num]\n",
    "predict(model, image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
